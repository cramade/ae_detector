{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from init_mnist import MNIST\n",
    "from ipywidgets import interact\n",
    "\n",
    "from cw_attack import CW_Attack\n",
    "from train_cnn_mnist import CNN, CNNTrain\n",
    "import torchattacks\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "def torch_img_show(image, label):\n",
    "  npimg = image.cpu().numpy()\n",
    "  fig = plt.figure(figsize = (5, 15))\n",
    "  plt.imshow(image, cmap='gray')\n",
    "  plt.title(label)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model loaded\n"
     ]
    }
   ],
   "source": [
    "trainer = CNNTrain()\n",
    "trainer.model_train()\n",
    "\n",
    "model = trainer.model\n",
    "#model.eval()\n",
    "mnist = trainer.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label: 0, Predcited: 0\n",
      "CW(model_name=CNN, device=cpu, attack_mode=default, targeted=False, normalization_used=False, c=1, kappa=0, steps=1000, lr=0.01)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data\n",
    "images, labels = next(iter(mnist.test_loader))\n",
    "\n",
    "true_y = labels.item()\n",
    "pred_y = torch.argmax(model(images)).item()\n",
    "print(f\"True Label: {true_y}, Predcited: {pred_y}\")\n",
    "\n",
    "# CW Attack\n",
    "attack = torchattacks.CW(model, c=1, steps=1000, lr=0.01)\n",
    "#attack.set_mode_targeted_random(10)\n",
    "#attack.set_mode_targeted_least_likely(3)\n",
    "print(attack)\n",
    "adv_images = attack(images, labels)\n",
    "\n",
    "# Evaluate\n",
    "adv_pred = model(adv_images)\n",
    "adv_pred_y = torch.argmax(adv_pred).item()\n",
    "\n",
    "title = f\"{true_y} -> {adv_pred_y}\"\n",
    "torch_img_show(adv_images[0][0], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('data') != True:\n",
    "#   os.mkdir('data')\n",
    "\n",
    "# if os.path.exists('data/test') != True:\n",
    "#   os.mkdir('data/test')\n",
    "# for i in range (0, 10):\n",
    "#   if os.path.exists(f'data/test/{i}') != True:\n",
    "#     os.mkdir(f'data/test/{i}')\n",
    "\n",
    "# if os.path.exists('data/train') != True:\n",
    "#   os.mkdir('data/train')\n",
    "# for i in range (0, 10):\n",
    "#   if os.path.exists(f'data/train/{i}') != True:\n",
    "#     os.mkdir(f'data/train/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(0, len(mnist.data_test)):\n",
    "#   image, label = mnist.data_test[idx]\n",
    "\n",
    "#   images = image.unsqueeze(0)\n",
    "#   labels = torch.tensor(label, dtype=torch.int8)\n",
    "#   adv_images = attack(images, labels)\n",
    "\n",
    "#   path = f\"data/test/{labels.item()}/{idx}.png\"\n",
    "#   if os.path.exists(url) != True:\n",
    "#     save_image(adv_images, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 Predict: 0\n",
      "Loss: 7083.64, Correct: 36.85% = 3685/10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(), # regularazation : range of 0~1\n",
    "])\n",
    "\n",
    "adv_data = ImageFolder(root='data/test', transform=transform_test)\n",
    "adv_loader = DataLoader(dataset=adv_data, batch_size=1, shuffle=False)\n",
    "\n",
    "def model_predict(image, label):\n",
    "    with torch.no_grad():\n",
    "        image_torch = image.data.view(1, 1, 28, 28).float().to(device)\n",
    "        predict = model(image_torch)\n",
    "        print(f\"Label: {label} Predict: {torch.argmax(predict)}\")\n",
    "        return predict\n",
    "\n",
    "def model_evaluate(test_loader):\n",
    "    test_loss = 0\n",
    "    correct_cnt = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for image, label in test_loader:\n",
    "            predict_logit = model(image)\n",
    "            test_loss += criterion(predict_logit, label).item()\n",
    "            predict = torch.argmax(predict_logit)\n",
    "            correct_cnt += predict.eq(label.view_as(predict)).sum().item()\n",
    "        print(f\"Loss: {test_loss:.2f}, Correct: {(correct_cnt/len(test_loader))*100:.2f}% = {correct_cnt}/{len(test_loader)}\")\n",
    "        return test_loss, correct_cnt\n",
    "\n",
    "images, labels =adv_data[1]\n",
    "pred = model_predict(images[0], labels)\n",
    "model_evaluate(adv_loader)\n",
    "print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an autoencoder to distinguish adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 28*28),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "       out = x.view(x.size(0), -1)\n",
    "       encoded = self.encoder(out)\n",
    "       decoded = self.decoder(encoded)\n",
    "       return decoded\n",
    "\n",
    "\n",
    "path = \"ae_model/ae_model.pt\"\n",
    "if(os.path.isfile(path)):\n",
    "    autoencoder = torch.load(path)\n",
    "else:\n",
    "    autoencoder = AutoEncoder().to(device)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "    loss = torch.nn.MSELoss().to(device)\n",
    "\n",
    "    # trains model\n",
    "    for epoch in range(15):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for X, Y in mnist.train_loader:\n",
    "            # image is already size of (28x28), no reshape\n",
    "            # label is not one-hot encoded\n",
    "            X = X.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            autoencoder.train()\n",
    "            hypothesis = autoencoder(X).reshape(-1, 28, 28)\n",
    "            cost = loss(hypothesis, X)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += cost / 15\n",
    "\n",
    "        print(f'[Epoch: {(epoch+1):>4}] cost = {avg_cost:>.9}')\n",
    "\n",
    "    autoencoder.train()\n",
    "    torch.save(autoencoder, \"ae_model/ae_model.pt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference between AE inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cal_mnist_diff(model, data, range, avg=0, std=0):\n",
    "  decoded = model(data)\n",
    "  o_diff = (np.abs(data.reshape(-1, 28, 28) - decoded)).reshape(-1, 28*28)\n",
    "  o_diff_sum = np.sum(o_diff, axis=1)\n",
    "  #print(o_diff_sum)\n",
    "\n",
    "  # for training (calculate avg and std)\n",
    "  if(avg == 0 and std == 0):\n",
    "    avg = np.average(o_diff_sum)\n",
    "    std = np.std(o_diff_sum)\n",
    "    print(f\"[Avg]: {avg:.2f} [Std]: {std:.2f} [Range]: {avg-std*range:.2f} ~ {avg+std*range:.2f}\")\n",
    "\n",
    "  # Search indices that is out of range\n",
    "  search_result = np.where((o_diff_sum > avg+std*range) | (o_diff_sum  < avg-std*range))\n",
    "\n",
    "  n_total = len(o_diff_sum)\n",
    "  n_out_of_bound = len(search_result[0])\n",
    "\n",
    "  print(f\"[Out-of-bound Ratio]]: {(n_out_of_bound/n_total)*100:.2f}% ({n_out_of_bound}/{n_total})\")\n",
    "  return o_diff_sum, avg, std\n",
    "\n",
    "diff, avg, std = cal_mnist_diff(autoencoder, train_x, 5)\n",
    "test_diff = cal_mnist_diff(normal_ae_model, test_x, 5, avg, std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
